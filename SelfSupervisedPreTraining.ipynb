{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Supervised Pre-training [30 marks]\n",
    "\n",
    "### What is rotation classification task?\n",
    "One important self-training task is the task of rotation classification. Here given a set of unlabeled images, we randomly rotate it to either of the following angles {0, 90, 180, 270} degrees and train a image rotation classifier which predicts by what angle the initial image has been rotated to generate the current image. The problem is set up as a classification problem since we only rotate our images by a fixed set of angles as mentioned before and the corresponding ground truth labels being {0, 1, 2, 3}.\n",
    "\n",
    "<center>\n",
    "<img src=\"./fig/Self-training-rot.png\" width=\"524\" height=\"300\">\n",
    "</center>\n",
    "\n",
    "Once the self-training based pretraining is done, we strip away the final classification layer(which is a linear layer) and add Convolutional or linear layers as per the downstream task's requirement.\n",
    "\n",
    "\n",
    "### Details of this problem statement.\n",
    "\n",
    "1. Take the CIFAR-10 dataset, each class has 5000 samples and there are 10 classes.\n",
    "Split the dataset in 2 parts (A) 40000 and (B) 10000 each with equal number of samples per class in each split.\n",
    "2. Discard the labels of the samples in the first set.\n",
    "3. Take a resnet-18 (initialised) and strip the imagenet classification layer with a 4 way classification layer.\n",
    "4. Train this network on the self-training task of classifiying the rotation of the image.\n",
    "5. Once this self-supervised pretraining is done, strip the classification layer and add a classification layer for CIFAR-10 classification this is finetuned on the set B for the task of image classification.\n",
    "6. Log the loss(cross entropy) and accuracies for both the pre-training task and classfication task.\n",
    "\n",
    "You are free tou use ML API of your choice. Your work will be checked for plagiarism!!\n",
    "\n",
    "### Citations and helpful references \n",
    "[1]. https://www.youtube.com/watch?v=8L10w1KoOU8&t=694s <br>\n",
    "[2]. https://openaccess.thecvf.com/content_CVPR_2019/papers/Feng_Self-Supervised_Representation_Learning_by_Rotation_Feature_Decoupling_CVPR_2019_paper.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# CIFAR-10 data transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load CIFAR-10 dataset\n",
    "cifar_train = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "cifar_test = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "# Define data loaders\n",
    "train_loader_A = torch.utils.data.DataLoader(cifar_train, batch_size=64, shuffle=True, num_workers=2)\n",
    "train_loader_B = torch.utils.data.DataLoader(cifar_test, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "# Split dataset into parts A and B\n",
    "data_A = []\n",
    "data_B = []\n",
    "labels_B = []\n",
    "\n",
    "for data, label in train_loader_A:\n",
    "    data_A.append(data)\n",
    "\n",
    "for data, label in train_loader_B:\n",
    "    data_B.append(data)\n",
    "    labels_B = labels_B + label.toList()\n",
    "\n",
    "print(labels_B.shape)\n",
    "data_A = torch.cat(data_A, dim=0)\n",
    "data_B = torch.cat(data_B, dim=0)\n",
    "labels_B = torch.tensor(labels_B)\n",
    "\n",
    "# Strip labels of the samples in set A\n",
    "labels_A = torch.zeros(len(data_A), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet-18 model with a 4-way rotation classification layer\n",
    "class RotationClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RotationClassifier, self).__init__()\n",
    "        resnet = resnet18(pretrained=True)\n",
    "        # Remove the classification layer\n",
    "        resnet = nn.Sequential(*list(resnet.children())[:-1])\n",
    "        self.resnet = nn.Sequential(*resnet)\n",
    "        self.fc = nn.Linear(resnet.fc.in_features, 4)  # 4-way rotation classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the rotation classifier\n",
    "rotation_classifier = RotationClassifier()\n",
    "\n",
    "# Train the rotation classifier on set A\n",
    "criterion_rotation = nn.CrossEntropyLoss()\n",
    "optimizer_rotation = optim.SGD(rotation_classifier.parameters(), lr=0.001, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop for rotation classification task\n",
    "for epoch in range(5): \n",
    "    running_loss = 0.0\n",
    "    for i, inputs in enumerate(data_A, 0):\n",
    "        optimizer_rotation.zero_grad()\n",
    "        outputs = rotation_classifier(inputs)\n",
    "        loss = criterion_rotation(outputs, labels_A)\n",
    "        loss.backward()\n",
    "        optimizer_rotation.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch + 1}, Loss: {running_loss / len(data_A)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip the classification layer for fine-tuning on CIFAR-10 classification task\n",
    "classification_model = nn.Sequential(*list(rotation_classifier.resnet.children())[:-1])\n",
    "fc_layer = nn.Linear(classification_model[-1].in_features, 10)  # 10 classes for CIFAR-10\n",
    "classification_model.add_module('fc', fc_layer)\n",
    "\n",
    "# Fine-tune on set B for CIFAR-10 classification\n",
    "criterion_classification = nn.CrossEntropyLoss()\n",
    "optimizer_classification = optim.SGD(classification_model.parameters(), lr=0.001, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop for CIFAR-10 classification task\n",
    "for epoch in range(5): \n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, inputs in enumerate(data_B, 0):\n",
    "        optimizer_classification.zero_grad()\n",
    "        outputs = classification_model(inputs)\n",
    "        loss = criterion_classification(outputs, labels_B)\n",
    "        loss.backward()\n",
    "        optimizer_classification.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels_B.size(0)\n",
    "        correct += predicted.eq(labels_B).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Epoch {epoch + 1}, Loss: {running_loss / len(data_B)}, Accuracy: {accuracy}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "49598912cb7efc65e0007e347a7051cc5ac4c91b95dad2ffbc631da6724968c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
